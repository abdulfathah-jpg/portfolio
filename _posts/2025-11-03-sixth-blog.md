---
title: "Evaluating ChatGPT on NLP and NER"
excerpt_separator: "<!--more-->"
categories:
  - project1
tags:
  - Projects
  - Evalaution
  - Machine Learning
image: images/nlp.jpg
---

I consulted the illustrious and ever-wise ChatGPT to shed light on the meanings of Natural Language Processing (NLP) and Named Entity Recognition (NER), and I also referred to two separate Data Camp blog posts (one on [NLP](https://www.datacamp.com/blog/what-is-natural-language-processing) and the other on [NER](https://www.datacamp.com/blog/what-is-named-entity-recognition-ner)) explaining these concepts. Yet, as a conscious seeker of knowledge who does not indulge in uncritical taqlīd, this blog post engage in a careful and reasoned evaluation (ijtihād) of both sources

<!--more-->

In the world of Artificial Intelligence, Natural Language Processing (NLP) fills in to enable computers understand, interpret, and generate human language. As such, they employ the human field of linguistics and its own capacity for machine learning to process and analyze text or speech. They power applications like chatbots, translation systems, sentiment analysis, information extraction, and contribute to a smoother and productive intersection of human and mechanical world. Within NLP, Named Entity Recognition (NER) identifies and classifies key pieces of information such as names of people, organizations, locations, dates, monetary values, and more within text. Essentially, they transform unstructured text into structured data for computational analyses.

I consulted the illustrious and ever-wise ChatGPT to shed light on the meanings of these two concepts, and I also referred to two separate Data Camp blog posts (one on [NLP](https://www.datacamp.com/blog/what-is-natural-language-processing) and the other on [NER](https://www.datacamp.com/blog/what-is-named-entity-recognition-ner)) explaining these concepts. Yet, as a conscious seeker of knowledge who does not indulge in uncritical taqlīd, below I engage in a careful and reasoned evaluation (ijtihād) of both sources.

## Natural Language Processing (NLP)

There are two components in the DataCamp post that were explained more clearly and in a detailed manner than the ChatGPT explanation. DataCamp post includes a concise and straight-to-the-point listing of ‘components’ and ‘techniques’ of Natural Language Processing (NLP) that was mostly missed in the later. The ChatGPT does mention some of them, but does not discuss them in detail or present them in listed manner that helps a beginner to form a comprehensive idea of the NLP. DataCamp lists four core linguistic components of NLP -syntax, semantics, pragmatics, and discourse – and gives concise definitions and examples for each. When it comes to the techniques employed by NLP, DataCamp defines specific NLP techniques such as tokenization, parsing, lemmatization, Named Entity Recognition (NER), and sentiment analyses. I also believe that the DataCamp post discuss the real-life usage of NLP in a much more detailed manner with examples that easily catch the eyes of the beginner.

As far ChatGPT is concerned, it discusses grammar/syntax, but does not conceives them as components or mention other components such as pragmatics or discourse. Moreover, it completely misses fine-grained linguistic tasks like parsing in-depth or lemmatization, and has been more conservative with definitions or real-life examples. Very often, it meant that in favoring a flowing narrative over depth, it over simplifies the very processes and techniques involved in NLP. Take the case of “Step 4: Training Objective” in ChatGPT conversation, where the whole training objective gets reduced to a single technique of predicting the next word based on previous ONES. It is true that it’s a very common formulation in language modeling, but not the only technique and certainly not a comprehensive one. ChatGPT completely misses particularly relevant sections on challenges or future directions in NLP mechanism. The DataCamp is hugely useful in understanding the later such as transfer learning, multimodal NLP, real-time processing, and ethical and responsible AI.

Nevertheless, ChatGPT excels in several other ways over DataCamp. One of them has already been hinted at: the general workflow of NLP. ChatGPT walks us through the linear pipeline of steps involved: data collection, preprocessing, model training, finetuning, and finally leading up to inference. I am particularly carried away by the pre-processing where it explains normalization and how embeddings are carried out or tokens are converted into numbers. Despite being narrower, visualization of the process through python formats is particularly helpful and enticing for beginners interested in Digital Humanities, as they might have already been familiar with many such notions and would be excited to see these notions being relevant to NLP. Further, I see that ChatGPT mentions the historical progression of NLP approaches from rule-based to statistical to neural-based models. This also means that ChatGPT is more familiar with the present scenario of NLP, the transformer-based models and its usage of “self-attention.” The DataCamp article does not mention them in a precise manner, and whenever they were hinted at, they are tucked into a general and almost ahistorical section under future trends. 

For these reasons, I found that ChatGPT has been particularly helpful in explaining the concept of Natural Language Processing (NLP) in a more concise, less wordy, and more enticing way while also presenting information in a stripped down, essential form. The workflow strategy, as opposed to the detailed linguistic and conceptual strategy followed by DataCamp, would be preferred by students of Digital Humanities who had familiarity with these notions. The ChatGPT answers are also preferred because rather than bogging down into definitions, the focus has been on the process and understanding the big picture of how NLP works

## Named Entity Recognition (NER)

The DataCamp article stands out in its explanation of Named Entity Recognition (NER) by providing a structured overview that is often missing in ChatGPT’s response. It breaks down NER into its essential stages - tokenization, entity identification, classification, contextual analysis, and post-processing - and explains each stage with clarity and illustrative examples that make the process tangible for beginners. Additionally, the article highlights techniques used in NER and distinguishes between rule-based methods, statistical approaches, and modern deep learning models. I also found that the DataCamp post’s resume example was particularly engaging, as it demonstrates how NER works in real-life applications while introducing us to various specialized models. These examples make the concept accessible and practical for newcomers to NLP.

Regarding ChatGPT, although it touches on the basic workings of NER and briefly references rule-based and machine learning approaches, it does not offer the step-by-step framework that DataCamp clearly lays out. For instance, it does not detail the five-step NER pipeline or elaborate on how contextual or post-processing stages gradually resolve ambiguity. I particularly feel that the code examples are presented without much explanation or contextual guidance - they are visually pleasing, but a beginner might find it hard to follow what is going on behind the scenes. The examples are appealing for Digital Humanities students who enjoy seeing code outputs, but they lack the conceptual background to fully appreciate the process. ChatGPT oversimplifies certain aspects, like entity ambiguity or nested entities, and completely misses the discussion of challenges and future directions such as domain adaptation, annotation issues, or ethical implications. 

Nevertheless, ChatGPT excels in several ways that DataCamp does not. One of them is certainly its inclusion of direct, runnable code using spaCy and Hugging Face Transformers. This hands-on demonstration bridges the gap between theory and implementation and is especially useful for students eager to experiment. Additionally, ChatGPT adds a comparison table between two illustrated libraries and outline their strengths and weaknesses. It shows the real-world relevance of different tools and provides guidance on which to choose for specific use cases. The workflow presentation, showing how a model processes text step-by-step, is also more immediate and exciting.

Choosing between the DataCamp post and ChatGPT’s explanation is difficult, as both serve different learning preferences and appeals. However, for this discussion of NER, I would ultimately choose DataCamp. ChatGPT’s approach is concise, modern, and implementation-oriented, but DataCamp provides the conceptual foundation and real-world framing that make the understanding of NER both deeper and more durable. It also gives a more rounded understanding of how NER fits into the larger NLP ecosystem.

